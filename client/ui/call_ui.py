"""
Giao diá»‡n Video/Audio Call vá»›i WebRTC thá»±c
"""

from tkinter import Frame, Label, Button, Toplevel, Canvas
from tkinter import CENTER, BOTH
from common.protocol import Protocol, MessageType
import time
import threading
import base64
import cv2
import numpy as np
from PIL import Image, ImageTk

# WebRTC imports
try:
    import cv2
    import numpy as np
    from PIL import Image, ImageTk
    import pyaudio
    WEBRTC_AVAILABLE = True
except ImportError:
    WEBRTC_AVAILABLE = False
    print("âš ï¸  WebRTC dependencies not available. Install: opencv-python, pyaudio")

class CallUI:
    def __init__(self, client, peer_username, call_type, is_caller=False):
        self.client = client
        self.peer = peer_username
        self.call_type = call_type  # "video" or "audio"
        self.is_caller = is_caller
        self.colors = client.colors
        self.call_active = False
        self.start_time = None
        
        # WebRTC components
        self.video_capture = None
        self.audio_stream = None
        self.audio_output = None
        self.is_muted = False
        self.is_camera_on = True
        
        # Táº¡o cá»­a sá»• call
        self.window = Toplevel(client.root)
        self.window.title(f"{'Video' if call_type == 'video' else 'Audio'} Call")
        
        if call_type == "video":
            self.window.geometry("800x600")
        else:
            self.window.geometry("400x300")
        
        # Center window
        self.window.update_idletasks()
        w = 800 if call_type == "video" else 400
        h = 600 if call_type == "video" else 300
        x = (self.window.winfo_screenwidth() // 2) - w // 2
        y = (self.window.winfo_screenheight() // 2) - h // 2
        self.window.geometry(f"{w}x{h}+{x}+{y}")
        
        # Main container
        self.main_container = Frame(self.window, bg="#1a1a1a")
        self.main_container.pack(fill=BOTH, expand=True)
        
        if is_caller:
            self._create_calling_ui()
        else:
            self._create_incoming_ui()
        
        # LÆ°u reference
        self.client.current_call = self
        
        # Handle window close
        self.window.protocol("WM_DELETE_WINDOW", self._end_call)
    
    def _create_calling_ui(self):
        """UI khi Ä‘ang gá»i Ä‘i"""
        # Video canvas (if video call)
        if self.call_type == "video":
            self.video_canvas = Canvas(
                self.main_container, 
                bg="#000000", 
                width=640, 
                height=480,
                highlightthickness=0
            )
            self.video_canvas.pack(padx=20, pady=20)
            
            # Placeholder text
            self.placeholder_text = self.video_canvas.create_text(
                320, 240,
                text="ğŸ“¹ Äang káº¿t ná»‘i...",
                font=("Arial", 24),
                fill="#666666"
            )
        
        # Status
        self.status_label = Label(
            self.main_container,
            text=f"Äang gá»i {self.peer}...",
            font=("Arial", 16),
            bg="#1a1a1a",
            fg="white"
        )
        self.status_label.pack(pady=10)
        
        # Timer
        self.timer_label = Label(
            self.main_container,
            text="00:00",
            font=("Arial", 14),
            bg="#1a1a1a",
            fg="#888888"
        )
        self.timer_label.pack(pady=5)
        self.timer_label.pack_forget()
        
        # Controls
        self._create_call_controls()
    
    def _create_incoming_ui(self):
        """UI khi nháº­n cuá»™c gá»i"""
        # Video placeholder (if video call)
        if self.call_type == "video":
            video_frame = Frame(self.main_container, bg="#000000", height=250)
            video_frame.pack(fill="x", padx=20, pady=20)
            video_frame.pack_propagate(False)
            
            Label(
                video_frame,
                text="ğŸ“¹",
                font=("Arial", 60),
                bg="#000000",
                fg="#666666"
            ).place(relx=0.5, rely=0.5, anchor=CENTER)
        
        # Caller info
        Label(
            self.main_container,
            text=f"{self.peer}",
            font=("Arial", 20, "bold"),
            bg="#1a1a1a",
            fg="white"
        ).pack(pady=20)
        
        Label(
            self.main_container,
            text=f"Cuá»™c gá»i {'video' if self.call_type == 'video' else 'thoáº¡i'} Ä‘áº¿n...",
            font=("Arial", 14),
            bg="#1a1a1a",
            fg="#cccccc"
        ).pack(pady=5)
        
        # Answer/Reject buttons
        buttons_frame = Frame(self.main_container, bg="#1a1a1a")
        buttons_frame.pack(pady=30)
        
        Button(
            buttons_frame,
            text="âŒ",
            font=("Arial", 30),
            bg="#ff3b30",
            fg="white",
            width=5,
            height=2,
            bd=0,
            cursor="hand2",
            command=self._reject_call
        ).pack(side="left", padx=20)
        
        Button(
            buttons_frame,
            text="âœ…",
            font=("Arial", 30),
            bg="#34c759",
            fg="white",
            width=5,
            height=2,
            bd=0,
            cursor="hand2",
            command=self._accept_call
        ).pack(side="left", padx=20)
    
    def _create_call_controls(self):
        """Táº¡o cÃ¡c nÃºt Ä‘iá»u khiá»ƒn cuá»™c gá»i"""
        controls_frame = Frame(self.main_container, bg="#1a1a1a")
        controls_frame.pack(pady=10)
        
        # Mute button
        self.mute_btn = Button(
            controls_frame,
            text="ğŸ¤",
            font=("Arial", 20),
            bg="#333333",
            fg="white",
            width=4,
            height=2,
            bd=0,
            cursor="hand2",
            command=self._toggle_mute
        )
        self.mute_btn.pack(side="left", padx=10)
        
        # Camera button (if video)
        if self.call_type == "video":
            self.camera_btn = Button(
                controls_frame,
                text="ğŸ“¹",
                font=("Arial", 20),
                bg="#333333",
                fg="white",
                width=4,
                height=2,
                bd=0,
                cursor="hand2",
                command=self._toggle_camera
            )
            self.camera_btn.pack(side="left", padx=10)
        
        # End call button
        Button(
            controls_frame,
            text="ğŸ“",
            font=("Arial", 20),
            bg="#ff3b30",
            fg="white",
            width=4,
            height=2,
            bd=0,
            cursor="hand2",
            command=self._end_call
        ).pack(side="left", padx=10)
    
    def _accept_call(self):
        """Cháº¥p nháº­n cuá»™c gá»i"""
        Protocol.send_message(
            self.client.socket,
            MessageType.CALL_ACCEPT,
            {
                "caller": self.peer,
                "recipient": self.client.username
            }
        )
        
        # Chuyá»ƒn sang UI Ä‘ang gá»i
        for widget in self.main_container.winfo_children():
            widget.destroy()
        
        self._create_calling_ui()
        self._start_call_session()
    
    def _reject_call(self):
        """Tá»« chá»‘i cuá»™c gá»i"""
        Protocol.send_message(
            self.client.socket,
            MessageType.CALL_REJECT,
            {
                "caller": self.peer,
                "recipient": self.client.username
            }
        )
        
        self._cleanup_media()
        self.window.destroy()
        if self.client.current_call == self:
            self.client.current_call = None
    
    def _end_call(self):
        """Káº¿t thÃºc cuá»™c gá»i"""
        if self.call_active:
            Protocol.send_message(
                self.client.socket,
                MessageType.CALL_END,
                {
                    "peer": self.peer
                }
            )
        
        self._cleanup_media()
        self.window.destroy()
        if self.client.current_call == self:
            self.client.current_call = None
    
    def _start_call_session(self):
        """Báº¯t Ä‘áº§u phiÃªn gá»i - Khá»Ÿi Ä‘á»™ng media"""
        self.call_active = True
        self.start_time = time.time()
        
        # Update status
        self.status_label.config(text=f"Äang gá»i vá»›i {self.peer}")
        
        # Show timer
        self.timer_label.pack(pady=5)
        self._update_timer()
        
        # Khá»Ÿi Ä‘á»™ng media streaming
        if WEBRTC_AVAILABLE:
            threading.Thread(target=self._start_media_streaming, daemon=True).start()
        else:
            self.status_label.config(
                text="âš ï¸ WebRTC khÃ´ng kháº£ dá»¥ng. Chá»‰ demo UI.",
                fg="#ff9500"
            )
    
    def _start_media_streaming(self):
        """Khá»Ÿi Ä‘á»™ng video/audio streaming"""
        try:
            # Video streaming
            if self.call_type == "video" and self.is_camera_on:
                self._start_video_capture()
            
            # Audio streaming
            self._start_audio_streaming()
            
        except Exception as e:
            print(f"Error starting media: {e}")
            self.window.after(0, lambda: self.status_label.config(
                text=f"âš ï¸ Lá»—i media: {e}",
                fg="#ff3b30"
            ))
    
    def _start_video_capture(self):
        """Báº¯t Ä‘áº§u capture video tá»« webcam"""
        try:
            self.video_capture = cv2.VideoCapture(0)
            
            if not self.video_capture.isOpened():
                raise Exception("KhÃ´ng thá»ƒ má»Ÿ webcam")
            
            # Set resolution
            self.video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            # XÃ³a placeholder
            if hasattr(self, 'placeholder_text'):
                self.video_canvas.delete(self.placeholder_text)
            
            # Báº¯t Ä‘áº§u video loop
            self._update_video_frame()
            
        except Exception as e:
            print(f"Video capture error: {e}")
    
    def _update_video_frame(self):
        """Cáº­p nháº­t frame video: Hiá»ƒn thá»‹ local + Gá»­i Ä‘i"""
        if not self.call_active or not self.is_camera_on:
            return

        # --- Cáº¤U HÃŒNH (Dá»… dÃ ng Ä‘iá»u chá»‰nh táº¡i Ä‘Ã¢y) ---
        SEND_WIDTH, SEND_HEIGHT = 320, 240  # Giáº£m Ä‘á»™ phÃ¢n giáº£i khi gá»­i Ä‘á»ƒ mÆ°á»£t hÆ¡n
        JPEG_QUALITY = 50                   # Cháº¥t lÆ°á»£ng áº£nh (0-100), tháº¥p hÆ¡n = nhanh hÆ¡n
        FPS_TARGET = 30                     # Tá»‘c Ä‘á»™ khung hÃ¬nh
        # ---------------------------------------------

        try:
            ret, frame = self.video_capture.read()
            if ret:
                # 1. Xá»­ lÃ½ hiá»ƒn thá»‹ Local (Mirror)
                # Chá»‰ hiá»ƒn thá»‹ local náº¿u chÆ°a cÃ³ video tá»« Ä‘á»‘i phÆ°Æ¡ng (hoáº·c báº¡n cÃ³ thá»ƒ váº½ PIP)
                if not hasattr(self, 'has_peer_video') or not self.has_peer_video:
                    self._render_frame_to_canvas(frame)

                # 2. Xá»­ lÃ½ gá»­i Ä‘i (Send)
                try:
                    # Resize nhá» láº¡i Ä‘á»ƒ gá»­i qua máº¡ng
                    frame_small = cv2.resize(frame, (SEND_WIDTH, SEND_HEIGHT))
                    
                    # NÃ©n thÃ nh JPEG
                    _, buffer = cv2.imencode('.jpg', frame_small, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])
                    
                    # MÃ£ hÃ³a Base64
                    jpg_as_text = base64.b64encode(buffer).decode('utf-8')
                    
                    # Gá»­i qua socket
                    from common.protocol import Protocol, MessageType
                    Protocol.send_message(
                        self.client.socket,
                        MessageType.VIDEO_DATA,
                        {
                            "recipient": self.peer,
                            "data": jpg_as_text
                        }
                    )
                except Exception as e:
                    print(f"Send video error: {e}")

            # Loop
            self.window.after(int(1000/FPS_TARGET), self._update_video_frame)

        except Exception as e:
            print(f"Frame update error: {e}")

    def _render_frame_to_canvas(self, frame):
        """HÃ m há»— trá»£ váº½ frame lÃªn canvas"""
        try:
            # Convert mÃ u BGR -> RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Náº¿u lÃ  camera trÆ°á»›c (selfie), láº­t ngÆ°á»£c láº¡i cho giá»‘ng gÆ°Æ¡ng
            if not hasattr(self, 'has_peer_video') or not self.has_peer_video:
                 frame_rgb = cv2.flip(frame_rgb, 1)

            # Resize cho vá»«a Canvas
            canvas_width = self.video_canvas.winfo_width()
            canvas_height = self.video_canvas.winfo_height()
            if canvas_width > 1 and canvas_height > 1: # TrÃ¡nh lá»—i khi window chÆ°a load xong
                frame_rgb = cv2.resize(frame_rgb, (canvas_width, canvas_height))

            image = Image.fromarray(frame_rgb)
            photo = ImageTk.PhotoImage(image=image)

            self.video_canvas.delete("all")
            self.video_canvas.create_image(0, 0, image=photo, anchor="nw")
            self.video_canvas.image = photo # Giá»¯ tham chiáº¿u
        except Exception as e:
            pass
    
    def _start_audio_streaming(self):
        """Báº¯t Ä‘áº§u audio streaming"""
        try:
            # PyAudio setup
            p = pyaudio.PyAudio()
            
            # Input stream (microphone)
            if not self.is_muted:
                self.audio_stream = p.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=44100,
                    input=True,
                    frames_per_buffer=1024,
                    stream_callback=self._audio_callback
                )
                self.audio_stream.start_stream()
            
            # Output stream (speaker) - Ä‘á»ƒ nháº­n audio tá»« peer
            self.audio_output = p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=44100,
                output=True,
                frames_per_buffer=1024
            )
            
        except Exception as e:
            print(f"Audio streaming error: {e}")
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        """Callback xá»­ lÃ½ audio: Thu tá»« mic -> Gá»­i Ä‘i"""
        if self.call_active and not self.is_muted:
            try:
                # MÃ£ hÃ³a dá»¯ liá»‡u Ã¢m thanh raw sang Base64
                data_str = base64.b64encode(in_data).decode('utf-8')
                
                # Gá»­i qua socket
                # LÆ°u Ã½: socket.sendall an toÃ n vá»›i thread trong Python
                from common.protocol import Protocol, MessageType
                Protocol.send_message(
                    self.client.socket,
                    MessageType.AUDIO_DATA,
                    {
                        "recipient": self.peer,
                        "data": data_str
                    }
                )
            except Exception as e:
                # KhÃ´ng print lá»—i liÃªn tá»¥c Ä‘á»ƒ trÃ¡nh spam console
                pass
                
        return (in_data, pyaudio.paContinue)
    
    # ThÃªm cÃ¡c hÃ m nÃ y vÃ o class CallUI

    def process_incoming_video(self, data_str):
        """Xá»­ lÃ½ video nháº­n Ä‘Æ°á»£c tá»« Ä‘á»‘i phÆ°Æ¡ng"""
        try:
            # ÄÃ¡nh dáº¥u lÃ  Ä‘Ã£ cÃ³ video tá»« peer (Ä‘á»ƒ ngá»«ng hiá»ƒn thá»‹ local mirror)
            self.has_peer_video = True
            
            # Decode Base64 -> Bytes
            img_data = base64.b64decode(data_str)
            
            # Bytes -> Numpy Array
            np_arr = np.frombuffer(img_data, dtype=np.uint8)
            
            # Decode JPEG -> Frame
            frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            if frame is not None:
                self._render_frame_to_canvas(frame)
                
                # XÃ³a placeholder text náº¿u cÃ²n
                if hasattr(self, 'placeholder_text'):
                    self.video_canvas.delete(self.placeholder_text)
                    del self.placeholder_text
                    
        except Exception as e:
            print(f"Decode video error: {e}")

    def process_incoming_audio(self, data_str):
        """Xá»­ lÃ½ audio nháº­n Ä‘Æ°á»£c tá»« Ä‘á»‘i phÆ°Æ¡ng"""
        try:
            if self.audio_output:
                # Decode Base64 -> Raw bytes
                audio_data = base64.b64decode(data_str)
                # PhÃ¡t ra loa
                self.audio_output.write(audio_data)
        except Exception as e:
            print(f"Decode audio error: {e}")

    def _update_timer(self):
        """Cáº­p nháº­t bá»™ Ä‘áº¿m thá»i gian"""
        if self.call_active and self.start_time:
            elapsed = int(time.time() - self.start_time)
            minutes = elapsed // 60
            seconds = elapsed % 60
            self.timer_label.config(text=f"{minutes:02d}:{seconds:02d}")
            
            self.window.after(1000, self._update_timer)
    
    def _toggle_mute(self):
        """Báº­t/táº¯t mic"""
        self.is_muted = not self.is_muted
        
        if self.is_muted:
            self.mute_btn.config(bg="#ff3b30", text="ğŸ”‡")
            if self.audio_stream:
                self.audio_stream.stop_stream()
        else:
            self.mute_btn.config(bg="#333333", text="ğŸ¤")
            if self.audio_stream:
                self.audio_stream.start_stream()
    
    def _toggle_camera(self):
        """Báº­t/táº¯t camera"""
        self.is_camera_on = not self.is_camera_on
        
        if self.is_camera_on:
            self.camera_btn.config(bg="#333333", text="ğŸ“¹")
            if not self.video_capture:
                self._start_video_capture()
        else:
            self.camera_btn.config(bg="#ff3b30", text="ğŸ“µ")
            if self.video_capture:
                self.video_capture.release()
                self.video_capture = None
            
            # Show camera off message
            self.video_canvas.delete("all")
            self.video_canvas.create_text(
                320, 240,
                text="ğŸ“µ Camera táº¯t",
                font=("Arial", 24),
                fill="#666666"
            )
    
    def _cleanup_media(self):
        """Dá»n dáº¹p media resources"""
        self.call_active = False
        
        if self.video_capture:
            self.video_capture.release()
            self.video_capture = None
        
        if self.audio_stream:
            self.audio_stream.stop_stream()
            self.audio_stream.close()
            self.audio_stream = None
        
        if self.audio_output:
            self.audio_output.close()
            self.audio_output = None
    
    def on_call_accepted(self):
        """ÄÆ°á»£c gá»i khi cuá»™c gá»i Ä‘Æ°á»£c cháº¥p nháº­n"""
        self._start_call_session()
    
    def on_call_rejected(self):
        """ÄÆ°á»£c gá»i khi cuá»™c gá»i bá»‹ tá»« chá»‘i"""
        self.status_label.config(text=f"{self.peer} Ä‘Ã£ tá»« chá»‘i cuá»™c gá»i")
        self.window.after(2000, lambda: (self._cleanup_media(), self.window.destroy()))
        if self.client.current_call == self:
            self.client.current_call = None
    
    def on_call_ended(self):
        """ÄÆ°á»£c gá»i khi cuá»™c gá»i káº¿t thÃºc tá»« phÃ­a Ä‘á»‘i phÆ°Æ¡ng"""
        self.call_active = False
        self.status_label.config(text="Cuá»™c gá»i Ä‘Ã£ káº¿t thÃºc")
        self.window.after(2000, lambda: (self._cleanup_media(), self.window.destroy()))
        if self.client.current_call == self:
            self.client.current_call = None